{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\"model\": \"gpt-3.5-turbo\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/flaml/__init__.py:20: UserWarning: flaml.automl is not available. Please install flaml[automl] to enable AutoML functionalities.\n",
      "  warnings.warn(\"flaml.automl is not available. Please install flaml[automl] to enable AutoML functionalities.\")\n"
     ]
    }
   ],
   "source": [
    "from autogen import ConversableAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 03-04 04:57:54] {129} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
     ]
    }
   ],
   "source": [
    "onboarding_personal_information_agent = ConversableAgent(\n",
    "    name=\"Onboarding Personal Information Agent\",\n",
    "    system_message='''You are a helpful customer onboarding agent,\n",
    "    you are here to help new customers get started with our product.\n",
    "    Your job is to gather customer's name and location.\n",
    "    Do not ask for other information. Return 'TERMINATE' \n",
    "    when you have gathered all the information.''',\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 03-04 04:57:54] {129} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
     ]
    }
   ],
   "source": [
    "onboarding_topic_preference_agent = ConversableAgent(\n",
    "    name=\"Onboarding Topic preference Agent\",\n",
    "    system_message='''You are a helpful customer onboarding agent,\n",
    "    you are here to help new customers get started with our product.\n",
    "    Your job is to gather customer's preferences on news topics.\n",
    "    Do not ask for other information.\n",
    "    Return 'TERMINATE' when you have gathered all the information.''',\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"terminate\" in msg.get(\"content\").lower(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 03-04 04:57:54] {129} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
     ]
    }
   ],
   "source": [
    "customer_engagement_agent = ConversableAgent(\n",
    "    name=\"Customer Engagement Agent\",\n",
    "    system_message='''You are a helpful customer service agent\n",
    "    here to provide fun for the customer based on the user's\n",
    "    personal information and topic preferences.\n",
    "    This could include fun facts, jokes, or interesting stories.\n",
    "    Make sure to make it engaging and fun!\n",
    "    Return 'TERMINATE' when you are done.''',\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"terminate\" in msg.get(\"content\").lower(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_proxy_agent = ConversableAgent(\n",
    "    name=\"customer_proxy_agent\",\n",
    "    llm_config=False,\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"ALWAYS\",\n",
    "    is_termination_msg=lambda msg: \"terminate\" in msg.get(\"content\").lower(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating series of tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chats = [\n",
    "    {\n",
    "        \"sender\": onboarding_personal_information_agent,\n",
    "        \"recipient\": customer_proxy_agent,\n",
    "        \"message\": \n",
    "            \"Hello, I'm here to help you get started with our product.\"\n",
    "            \"Could you tell me your name and location?\",\n",
    "        \"summary_method\": \"reflection_with_llm\",\n",
    "        \"summary_args\": {\n",
    "            \"summary_prompt\" : \"Return the customer information \"\n",
    "                             \"into as JSON object only: \"\n",
    "                             \"{'name': '', 'location': ''}\",\n",
    "        },\n",
    "        \"max_turns\": 2,\n",
    "        \"clear_history\" : True\n",
    "    },\n",
    "    {\n",
    "        \"sender\": onboarding_topic_preference_agent,\n",
    "        \"recipient\": customer_proxy_agent,\n",
    "        \"message\": \n",
    "                \"Great! Could you tell me what topics you are \"\n",
    "                \"interested in reading about?\",\n",
    "        \"summary_method\": \"reflection_with_llm\",\n",
    "        \"max_turns\": 1,\n",
    "        \"clear_history\" : False\n",
    "    },\n",
    "    {\n",
    "        \"sender\": customer_proxy_agent,\n",
    "        \"recipient\": customer_engagement_agent,\n",
    "        \"message\": \"Let's find something fun to read.\",\n",
    "        \"max_turns\": 1,\n",
    "        \"summary_method\": \"reflection_with_llm\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the onboarding processÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mOnboarding Personal Information Agent\u001b[0m (to customer_proxy_agent):\n",
      "\n",
      "Hello, I'm here to help you get started with our product.Could you tell me your name and location?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/autogen/agentchat/chat.py:47: UserWarning: Repetitive recipients detected: The chat history will be cleared by default if a recipient appears more than once. To retain the chat history, please set 'clear_history=False' in the configuration of the repeating agent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mcustomer_proxy_agent\u001b[0m (to Onboarding Personal Information Agent):\n",
      "\n",
      "sohail\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mOnboarding Personal Information Agent\u001b[0m (to customer_proxy_agent):\n",
      "\n",
      "Thank you for providing your name. Could you also let me know your location, please?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcustomer_proxy_agent\u001b[0m (to Onboarding Personal Information Agent):\n",
      "\n",
      "putin\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mOnboarding Topic preference Agent\u001b[0m (to customer_proxy_agent):\n",
      "\n",
      "Great! Could you tell me what topics you are interested in reading about?\n",
      "Context: \n",
      "{'name': 'sohail', 'location': 'putin'}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcustomer_proxy_agent\u001b[0m (to Onboarding Topic preference Agent):\n",
      "\n",
      "trump\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mcustomer_proxy_agent\u001b[0m (to Customer Engagement Agent):\n",
      "\n",
      "Let's find something fun to read.\n",
      "Context: \n",
      "{'name': 'sohail', 'location': 'putin'}\n",
      "sohail from putin is interested in reading about trump.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mCustomer Engagement Agent\u001b[0m (to customer_proxy_agent):\n",
      "\n",
      "Hey Sohail from Putin! Did you know that Donald Trump was a reality TV star before becoming the President of the United States? He was the host of the show \"The Apprentice\" for many years! It's interesting to see how he transitioned from television to politics. Enjoy your reading about Trump! If you'd like to hear more fun facts or stories, feel free to let me know!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from autogen import initiate_chats\n",
    "\n",
    "chat_results = initiate_chats(chats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatResult(chat_id=None, chat_history=[{'content': \"Hello, I'm here to help you get started with our product.Could you tell me your name and location?\", 'role': 'assistant'}, {'content': 'sohail', 'role': 'user'}, {'content': 'Thank you for providing your name. Could you also let me know your location, please?', 'role': 'assistant'}, {'content': 'putin', 'role': 'user'}], summary=\"{'name': 'sohail', 'location': 'putin'}\", cost={'usage_including_cached_inference': {'total_cost': 0.00014649999999999998, 'gpt-3.5-turbo-0125': {'cost': 0.00014649999999999998, 'prompt_tokens': 188, 'completion_tokens': 35, 'total_tokens': 223}}, 'usage_excluding_cached_inference': {'total_cost': 0.00014649999999999998, 'gpt-3.5-turbo-0125': {'cost': 0.00014649999999999998, 'prompt_tokens': 188, 'completion_tokens': 35, 'total_tokens': 223}}}, human_input=[]),\n",
       " ChatResult(chat_id=None, chat_history=[{'content': \"Great! Could you tell me what topics you are interested in reading about?\\nContext: \\n{'name': 'sohail', 'location': 'putin'}\", 'role': 'assistant'}, {'content': 'trump', 'role': 'user'}], summary='sohail from putin is interested in reading about trump.', cost={'usage_including_cached_inference': {'total_cost': 5.4000000000000005e-05, 'gpt-3.5-turbo-0125': {'cost': 5.4000000000000005e-05, 'prompt_tokens': 66, 'completion_tokens': 14, 'total_tokens': 80}}, 'usage_excluding_cached_inference': {'total_cost': 5.4000000000000005e-05, 'gpt-3.5-turbo-0125': {'cost': 5.4000000000000005e-05, 'prompt_tokens': 66, 'completion_tokens': 14, 'total_tokens': 80}}}, human_input=[]),\n",
       " ChatResult(chat_id=None, chat_history=[{'content': \"Let's find something fun to read.\\nContext: \\n{'name': 'sohail', 'location': 'putin'}\\nsohail from putin is interested in reading about trump.\", 'role': 'assistant'}, {'content': 'Hey Sohail from Putin! Did you know that Donald Trump was a reality TV star before becoming the President of the United States? He was the host of the show \"The Apprentice\" for many years! It\\'s interesting to see how he transitioned from television to politics. Enjoy your reading about Trump! If you\\'d like to hear more fun facts or stories, feel free to let me know!', 'role': 'user'}], summary='Sohail from Putin is interested in reading about Donald Trump, who was a reality TV star before becoming the President of the United States.', cost={'usage_including_cached_inference': {'total_cost': 0.000299, 'gpt-3.5-turbo-0125': {'cost': 0.000299, 'prompt_tokens': 265, 'completion_tokens': 111, 'total_tokens': 376}}, 'usage_excluding_cached_inference': {'total_cost': 0.000299, 'gpt-3.5-turbo-0125': {'cost': 0.000299, 'prompt_tokens': 265, 'completion_tokens': 111, 'total_tokens': 376}}}, human_input=[])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'sohail', 'location': 'putin'}\n",
      "\n",
      "\n",
      "sohail from putin is interested in reading about trump.\n",
      "\n",
      "\n",
      "Sohail from Putin is interested in reading about Donald Trump, who was a reality TV star before becoming the President of the United States.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chat_result in chat_results:\n",
    "    print(chat_result.summary)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'usage_including_cached_inference': {'total_cost': 0.00014649999999999998, 'gpt-3.5-turbo-0125': {'cost': 0.00014649999999999998, 'prompt_tokens': 188, 'completion_tokens': 35, 'total_tokens': 223}}, 'usage_excluding_cached_inference': {'total_cost': 0.00014649999999999998, 'gpt-3.5-turbo-0125': {'cost': 0.00014649999999999998, 'prompt_tokens': 188, 'completion_tokens': 35, 'total_tokens': 223}}}\n",
      "\n",
      "\n",
      "{'usage_including_cached_inference': {'total_cost': 5.4000000000000005e-05, 'gpt-3.5-turbo-0125': {'cost': 5.4000000000000005e-05, 'prompt_tokens': 66, 'completion_tokens': 14, 'total_tokens': 80}}, 'usage_excluding_cached_inference': {'total_cost': 5.4000000000000005e-05, 'gpt-3.5-turbo-0125': {'cost': 5.4000000000000005e-05, 'prompt_tokens': 66, 'completion_tokens': 14, 'total_tokens': 80}}}\n",
      "\n",
      "\n",
      "{'usage_including_cached_inference': {'total_cost': 0.000299, 'gpt-3.5-turbo-0125': {'cost': 0.000299, 'prompt_tokens': 265, 'completion_tokens': 111, 'total_tokens': 376}}, 'usage_excluding_cached_inference': {'total_cost': 0.000299, 'gpt-3.5-turbo-0125': {'cost': 0.000299, 'prompt_tokens': 265, 'completion_tokens': 111, 'total_tokens': 376}}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chat_result in chat_results:\n",
    "    print(chat_result.cost)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
